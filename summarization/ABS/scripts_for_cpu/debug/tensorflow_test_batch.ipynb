{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function initialize_all_variables in module tensorflow.python.ops.variables:\n",
      "\n",
      "initialize_all_variables()\n",
      "    Returns an Op that initializes all variables.\n",
      "    \n",
      "    This is just a shortcut for `initialize_variables(all_variables())`\n",
      "    \n",
      "    Returns:\n",
      "      An Op that initializes all variables in the graph.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 100\n",
    "V = 10000\n",
    "D = 200\n",
    "C = 3\n",
    "\n",
    "y_c = tf.placeholder(tf.int32, shape=(batch_size, C))\n",
    "E = tf.Variable(tf.random_uniform((V, D), -1.0, 1.0)) # 乱数の設定を論文から参照する\n",
    "tilde_y_c = tf.nn.embedding_lookup(E, y_c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3, 200)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    #feed_dict={y_c: np.arange(batch_size)}\n",
    "    feed_dict={y_c: np.arange(batch_size*C).reshape(batch_size, C)}\n",
    "    print(sess.run(tilde_y_c, feed_dict=feed_dict).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "length = 100\n",
    "x = tf.placeholder(tf.int32, shape=(batch_size, None))\n",
    "y = x * 3\n",
    "sess = tf.Session()\n",
    "feed_dict = {x: np.arange(batch_size*length).reshape(batch_size, length)}\n",
    "output = sess.run(y, feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 60, 200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 100\n",
    "V = 10000\n",
    "D = 200\n",
    "\n",
    "length = 60\n",
    "x = tf.placeholder(tf.int32, shape=(batch_size, None))\n",
    "x = tf.Print(x, [x])\n",
    "F = tf.Variable(tf.random_uniform([V, D], -1.0, 1.0)) # 乱数の設定を参照\n",
    "tilde_x = tf.nn.embedding_lookup(F, x)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "feed_dict = {x: np.arange(batch_size*length).reshape(batch_size, length)}\n",
    "#feed_dict = {x: np.arange(batch_size)}\n",
    "output = sess.run(tilde_x, feed_dict=feed_dict)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "tilde_x:  TensorShape([Dimension(50), Dimension(None), Dimension(200)])\n",
      "slice:  TensorShape([Dimension(1), Dimension(None), Dimension(200)])\n",
      "slice:  TensorShape([Dimension(1), Dimension(None), Dimension(200)])\n",
      "--------------------------------------------------\n",
      "p: TensorShape([Dimension(50), Dimension(None)])\n",
      "slice:  TensorShape([Dimension(1), Dimension(None)])\n",
      "slice:  TensorShape([Dimension(1), Dimension(None)])\n",
      "--------------------------------------------------\n",
      "enc:  TensorShape([Dimension(50), Dimension(200)])\n",
      "(50, 200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 50\n",
    "V = 10000\n",
    "D = 200\n",
    "\n",
    "length = 6 # ここでは、length大きくしすぎると単語数がVより大きくなるので注意\n",
    "x = tf.placeholder(tf.int32, shape=(batch_size, None))\n",
    "F = tf.Variable(tf.random_uniform([V, D], -1.0, 1.0)) # 乱数の設定を参照\n",
    "tilde_x = tf.cast(tf.nn.embedding_lookup(F, x), tf.float32)\n",
    "p = tf.placeholder(tf.float32, shape=[batch_size, None])\n",
    "print('--------------------------------------------------')\n",
    "print('tilde_x: ', tilde_x.get_shape())\n",
    "print('slice: ', tf.slice(tilde_x, [0, 0, 0], [1, -1, -1]).get_shape())\n",
    "print('slice: ', tf.slice(tilde_x, [1, 0, 0], [1, -1, -1]).get_shape())\n",
    "print('--------------------------------------------------')\n",
    "print('p:', p.get_shape())\n",
    "print('slice: ', tf.slice(p, [0, 0], [1, -1]).get_shape())\n",
    "print('slice: ', tf.slice(p, [3, 0], [1, -1]).get_shape())\n",
    "print('--------------------------------------------------')\n",
    "for i in range(batch_size):\n",
    "    if i == 0:\n",
    "        enc = tf.matmul(tf.slice(p, [i, 0], [1, -1]), tf.reshape(tf.slice(tilde_x, [i, 0, 0], [1, -1, -1]), [-1, D]))\n",
    "    else:\n",
    "        temp = tf.matmul(tf.slice(p, [i, 0], [1, -1]), tf.reshape(tf.slice(tilde_x, [i, 0, 0], [1, -1, -1]), [-1, D]))\n",
    "        enc = tf.concat(0, [enc, temp])\n",
    "print('enc: ', enc.get_shape())\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "feed_dict = {x: np.arange(batch_size*length).reshape(batch_size, length), p: (np.ones((batch_size, length))/length).astype(np.float32)}\n",
    "output = sess.run(enc, feed_dict=feed_dict)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function embedding_lookup in module tensorflow.python.ops.embedding_ops:\n",
      "\n",
      "embedding_lookup(params, ids, partition_strategy='mod', name=None)\n",
      "    Looks up `ids` in a list of embedding tensors.\n",
      "    \n",
      "    This function is used to perform parallel lookups on the list of\n",
      "    tensors in `params`.  It is a generalization of\n",
      "    [`tf.gather()`](../../api_docs/python/array_ops.md#gather), where `params` is\n",
      "    interpreted as a partition of a larger embedding tensor.\n",
      "    \n",
      "    If `len(params) > 1`, each element `id` of `ids` is partitioned between\n",
      "    the elements of `params` according to the `partition_strategy`.\n",
      "    In all strategies, if the id space does not evenly divide the number of\n",
      "    partitions, each of the first `(max_id + 1) % len(params)` partitions will\n",
      "    be assigned one more id.\n",
      "    \n",
      "    If `partition_strategy` is `\"mod\"`, we assign each id to partition\n",
      "    `p = id % len(params)`. For instance,\n",
      "    13 ids are split across 5 partitions as:\n",
      "    `[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]`\n",
      "    \n",
      "    If `partition_strategy` is `\"div\"`, we assign ids to partitions in a\n",
      "    contiguous manner. In this case, 13 ids are split across 5 partitions as:\n",
      "    `[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]`\n",
      "    \n",
      "    The results of the lookup are concatenated into a dense\n",
      "    tensor. The returned tensor has shape `shape(ids) + shape(params)[1:]`.\n",
      "    \n",
      "    Args:\n",
      "      params: A list of tensors with the same type and which can be concatenated\n",
      "        along dimension 0. Each `Tensor` must be appropriately sized for the given\n",
      "        `partition_strategy`.\n",
      "      ids: A `Tensor` with type `int32` or `int64` containing the ids to be looked\n",
      "        up in `params`.\n",
      "      partition_strategy: A string specifying the partitioning strategy, relevant\n",
      "        if `len(params) > 1`. Currently `\"div\"` and `\"mod\"` are supported. Default\n",
      "        is `\"mod\"`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` with the same type as the tensors in `params`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `params` is empty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.embedding_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([3, 1, 6])\n",
    "t_onehot = np.zeros((3, 10))\n",
    "t_onehot[np.arange(3), t] = 1\n",
    "t_onehot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([Dimension(10000), Dimension(200)])\n",
      "TensorShape([Dimension(10000)])\n"
     ]
    }
   ],
   "source": [
    "print(F.get_shape())\n",
    "print(tf.argmax(F, 1).get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "dataset_path = '../../data/reuters/Business/year=2016/reuters_201611.csv'\n",
    "dataset = pd.read_csv(dataset_path, usecols=[5, 6])\n",
    "\n",
    "def first_sentence(sentences):\n",
    "    m = re.search('-(.*?)。', sentences)\n",
    "    return m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- title -----------------\n",
      "アングル：高まる欧州選挙リスク、英米の結果で身構える市場\n",
      "\n",
      "----------------- content -----------------\n",
      "［ロンドン １１日 ロイター］ - 英国民投票での欧州連合（ＥＵ）離脱派の勝利、米大統領選でのトランプ氏勝利──。既得権益層に対する大衆の反発を２度も見せつけられた金融市場は、来年に向け欧州で予定される国民投票や選挙で同様の事態が起こる可能性を覚悟し始めている。来年はオランダ、フランス、ドイツで選挙が予定されており、場合によってはイタリアと英国でも選挙が行われるかもしれない。当面の試金石となるのが、イタリアで１２月４日に予定される憲法改正の是非を問う国民投票。同じ日にオーストリアでは大統領選挙の決選投票のやり直しが実施され、候補者２人のうち１人は極右の人物だ。トランプ氏の財政拡張路線がインフレを招くとの見方から、欧米の国債相場はここ数日で全般に下落したが、中でもフランスとイタリアの下げ幅が大きいのも無理はない。ドイツの１０年国債利回りは１１日の週に１７ベーシスポイント（ｂｐ）程度上昇。これに対し、フランスとイタリアの１０年国債利回りは政治リスクも織り込んで約２５ｂｐ上昇している。フランス１０年国債利回りは０．７２％と、１月以来の高水準に迫り、ドイツとのスプレッドは４４ｂｐと、昨年７月以来で最大となった。ＩＮＧのシニア金利ストラテジスト、Martin Van Vliet氏は「英国の投票でアンチ既得権益層が勝ち、米国でも同じ結果が出たので、だれもが『来年はユーロ圏のどこで選挙があるのだろう』と調べ始めた。そう、フランスだ。こうした国々が危ないかもしれないと見て、市場はズームインし始めた」と話す。フランス大統領選の仕組みを踏まえると、極右政党・国民戦線（ＦＮ）のマリーヌ・ルペン党首が最終的に勝利する可能性は小さいと見られているが、世論調査によると、第１回投票での得票数はルペン氏が最多となりそうだ。しかも米英の投票が予想外の結果だったため、市場はもう世論調査を鵜呑みにしなくなるだろう。＜株や為替も＞動揺は債券市場以外にも広がっている。株式市場では、トランプ氏勝利による「リフレ」相場がポピュリズム（大衆迎合主義）や保護主義の恐れを覆い隠しているが、バンク・オブ・アメリカ・メリルリンチのデータによると、９日までの１週間で欧州株から１６億４０００万ドルが流出している。今年最も大荒れを演じた英ポンド相場がここにきて回復していることは、今後の欧州各国の選挙に対する懸念を映し出している、との指摘もある。三菱東京ＵＦＪ銀行のグローバル市場調査責任者、デレク・ハルペニー氏は「英国民投票での離脱派勝利はもはや、突出した出来事とは見られなくなり、ポピュリスト支持の投票が増える世界的な変革の始まりなのではないか、との見方広がっている。従って、（ポンドに対する）ユーロの下落は政治リスクプレミアムが英国から欧州に移る兆しと見るべきだ」と話す。＜伊首相に逆風＞トランプ氏の勝利により、１２月の国民投票で負ければ辞任すると表明しているイタリアのレンツィ首相にとって、情勢は一層厳しくなりそうだ。ほぼすべての世論調査が、投票で憲法改正の反対派が勝利するとの見通しを示している。こうした中、１１日に実施されたイタリア国債入札では落札利回りが過去１年超で最も高くなった。（Dhara Ranasinghe記者）\n",
      "\n",
      "----------------- first sentence -----------------\n",
      " 英国民投票での欧州連合（ＥＵ）離脱派の勝利、米大統領選でのトランプ氏勝利──\n"
     ]
    }
   ],
   "source": [
    "index = 560\n",
    "print('----------------- title -----------------')\n",
    "print(dataset.ix[index, 'title'])\n",
    "print()\n",
    "print('----------------- content -----------------')\n",
    "print(dataset.ix[index, 'content'])\n",
    "print()\n",
    "print('----------------- first sentence -----------------')\n",
    "print(first_sentence(dataset.ix[index, 'content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataFrameGroupBy in module pandas.core.groupby:\n",
      "\n",
      "class DataFrameGroupBy(NDFrameGroupBy)\n",
      " |  Class for grouping and aggregating relational data. See aggregate,\n",
      " |  transform, and apply functions on this object.\n",
      " |  \n",
      " |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = groupby(obj, ...)\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  obj : pandas object\n",
      " |  axis : int, default 0\n",
      " |  level : int, default None\n",
      " |      Level of MultiIndex\n",
      " |  groupings : list of Grouping objects\n",
      " |      Most users should ignore this\n",
      " |  exclusions : array-like, optional\n",
      " |      List of columns to exclude\n",
      " |  name : string\n",
      " |      Most users should ignore this\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      " |  some other brief notes about usage. When grouping by multiple groups, the\n",
      " |  result index will be a MultiIndex (hierarchical) by default.\n",
      " |  \n",
      " |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      " |  you can write code like:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      grouped = obj.groupby(keys, axis=axis)\n",
      " |      for key, group in grouped:\n",
      " |          # do something with the data\n",
      " |  \n",
      " |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      " |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      " |  method on each group, you can simply do:\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).std()\n",
      " |  \n",
      " |  rather than\n",
      " |  \n",
      " |  ::\n",
      " |  \n",
      " |      df.groupby(mapper).aggregate(np.std)\n",
      " |  \n",
      " |  You can pass arguments to these \"wrapped\" functions, too.\n",
      " |  \n",
      " |  See the online documentation for full exposition on these topics and much\n",
      " |  more\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  **Attributes**\n",
      " |  groups : dict\n",
      " |      {group name -> group labels}\n",
      " |  len(grouped) : int\n",
      " |      Number of groups\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrameGroupBy\n",
      " |      NDFrameGroupBy\n",
      " |      GroupBy\n",
      " |      _GroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  agg = aggregate(self, arg, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, arg, *args, **kwargs)\n",
      " |      Aggregate using input function or dict of {column ->\n",
      " |      function}\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function or dict\n",
      " |          Function to use for aggregating groups. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. If\n",
      " |          passed a dict, the keys must be DataFrame column names.\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |            - string cythonized function name\n",
      " |            - function\n",
      " |            - list of functions\n",
      " |            - dict of columns -> functions\n",
      " |            - nested dict of names -> dicts of functions\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Numpy functions mean/median/prod/sum/std/var are special cased so the\n",
      " |      default behavior is applying the function along axis=0\n",
      " |      (e.g., np.mean(arr_2d, axis=0)) as opposed to\n",
      " |      mimicking the default Numpy behavior (e.g., np.mean(arr_2d)).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : DataFrame\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |  \n",
      " |  boxplot = boxplot_frame_groupby(grouped, subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, **kwds)\n",
      " |      Make box plots from DataFrameGroupBy data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      grouped : Grouped DataFrame\n",
      " |      subplots :\n",
      " |          * ``False`` - no subplots will be used\n",
      " |          * ``True`` - create a subplot for each group\n",
      " |      column : column name or list of names, or vector\n",
      " |          Can be any valid input to groupby\n",
      " |      fontsize : int or string\n",
      " |      rot : label rotation angle\n",
      " |      grid : Setting this to True will show the grid\n",
      " |      ax : Matplotlib axis object, default None\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |      layout : tuple (optional)\n",
      " |          (rows, columns) for the layout of the plot\n",
      " |      kwds : other plotting keyword arguments to be passed to matplotlib boxplot\n",
      " |             function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict of key/value = group key/DataFrame.boxplot return value\n",
      " |      or DataFrame.boxplot return value in case subplots=figures=False\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas\n",
      " |      >>> import numpy as np\n",
      " |      >>> import itertools\n",
      " |      >>>\n",
      " |      >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n",
      " |      >>> index = pandas.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n",
      " |      >>> data = np.random.randn(len(index),4)\n",
      " |      >>> df = pandas.DataFrame(data, columns=list('ABCD'), index=index)\n",
      " |      >>>\n",
      " |      >>> grouped = df.groupby(level='lvl1')\n",
      " |      >>> boxplot_frame_groupby(grouped)\n",
      " |      >>>\n",
      " |      >>> grouped = df.unstack(level='lvl1').groupby(level=0, axis=1)\n",
      " |      >>> boxplot_frame_groupby(grouped, subplots=False)\n",
      " |  \n",
      " |  count(self)\n",
      " |      Compute count of group, excluding missing values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  all\n",
      " |      \n",
      " |      Return whether all elements are True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  any\n",
      " |      \n",
      " |      Return whether any element is True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  corr\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for pearson\n",
      " |          and spearman correlation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |  \n",
      " |  corrwith\n",
      " |      Compute pairwise correlation between rows or columns of two DataFrame\n",
      " |      objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      " |      drop : boolean, default False\n",
      " |          Drop missing indices from result, default returns union of all\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correls : Series\n",
      " |  \n",
      " |  cov\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `y` contains the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  cummax\n",
      " |          Return cumulative max over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummax : Series\n",
      " |  \n",
      " |  cummin\n",
      " |          Return cumulative minimum over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummin : Series\n",
      " |  \n",
      " |  describe\n",
      " |      Generate various summary statistics, excluding NaN values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : array-like, optional\n",
      " |          The percentiles to include in the output. Should all\n",
      " |          be in the interval [0, 1]. By default `percentiles` is\n",
      " |          [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.\n",
      " |      include, exclude : list-like, 'all', or None (default)\n",
      " |          Specify the form of the returned result. Either:\n",
      " |      \n",
      " |          - None to both (default). The result will include only\n",
      " |            numeric-typed columns or, if none are, only categorical columns.\n",
      " |          - A list of dtypes or strings to be included/excluded.\n",
      " |            To select all numeric types use numpy numpy.number. To select\n",
      " |            categorical objects use type object. See also the select_dtypes\n",
      " |            documentation. eg. df.describe(include=['O'])\n",
      " |          - If include is the string 'all', the output column-set will\n",
      " |            match the input one.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary: NDFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The output DataFrame index depends on the requested dtypes:\n",
      " |      \n",
      " |      For numeric dtypes, it will include: count, mean, std, min,\n",
      " |      max, and lower, 50, and upper percentiles.\n",
      " |      \n",
      " |      For object dtypes (e.g. timestamps or strings), the index\n",
      " |      will include the count, unique, most common, and frequency of the\n",
      " |      most common. Timestamps also include the first and last items.\n",
      " |      \n",
      " |      For mixed dtypes, the index will be the union of the corresponding\n",
      " |      output types. Non-applicable entries will be filled with NaN.\n",
      " |      Note that mixed-dtype outputs can only be returned from mixed-dtype\n",
      " |      inputs and appropriate use of the include/exclude arguments.\n",
      " |      \n",
      " |      If multiple values have the highest count, then the\n",
      " |      `count` and `most common` pair will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      The include, exclude arguments are ignored for Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  diff\n",
      " |      1st discrete difference of object\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming difference\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. versionadded: 0.16.1\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : DataFrame\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in this object.\n",
      " |  \n",
      " |  fillna\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : DataFrame\n",
      " |  \n",
      " |  hist\n",
      " |      Draw histogram of the DataFrame's series using matplotlib / pylab.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |      column : string or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      ax : matplotlib axes object, default None\n",
      " |      sharex : boolean, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in; Be aware, that passing in both an ax and sharex=True\n",
      " |          will alter all x axis labels for all subplots in a figure!\n",
      " |      sharey : boolean, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible\n",
      " |      figsize : tuple\n",
      " |          The size of the figure to create in inches by default\n",
      " |      layout: (optional) a tuple (rows, columns) for the layout of the histograms\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      kwds : other plotting keyword arguments\n",
      " |          To be passed to hist function\n",
      " |  \n",
      " |  idxmax\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be first index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax\n",
      " |  \n",
      " |  idxmin\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin\n",
      " |  \n",
      " |  mad\n",
      " |      \n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  pct_change\n",
      " |      Percent change over given number of periods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      By default, the percentage change is calculated along the stat\n",
      " |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      " |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      " |  \n",
      " |  quantile\n",
      " |      Return values at the given quantile over requested axis, a la\n",
      " |      numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Series or DataFrame\n",
      " |      \n",
      " |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          - If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |                         columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |  \n",
      " |  rank\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis: {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  skew\n",
      " |      \n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  take\n",
      " |      Analogous to ndarray.take\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : list / array of ints\n",
      " |      axis : int, default 0\n",
      " |      convert : translate neg to pos indices (default)\n",
      " |      is_copy : mark the returned frame as a copy\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |  \n",
      " |  tshift\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from NDFrameGroupBy:\n",
      " |  \n",
      " |  filter(self, func, dropna=True, *args, **kwargs)\n",
      " |      Return a copy of a DataFrame excluding elements from groups that\n",
      " |      do not satisfy the boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each subframe. Should return True or False.\n",
      " |      dropna : Drop groups that do not pass the filter. True by default;\n",
      " |          if False, groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> grouped = df.groupby(lambda x: mapping[x])\n",
      " |      >>> grouped.filter(lambda x: x['A'].sum() + x['B'].sum() > 0)\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed DataFrame on each group and\n",
      " |      return a DataFrame having the same indexes as the original object\n",
      " |      filled with the transformed values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each subframe\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> grouped = df.groupby(lambda x: mapping[x])\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from GroupBy:\n",
      " |  \n",
      " |  backfill(self, limit=None)\n",
      " |      Backward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  bfill = backfill(self, limit=None)\n",
      " |      Backward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumcount(self, ascending=True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      >>> self.apply(lambda x: Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumprod(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative product for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  cumsum(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative sum for each group\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs)\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionaility per group\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ffill = pad(self, limit=None)\n",
      " |      Forward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  first = f(self)\n",
      " |      Compute first of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows of each group.\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.head(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |                         columns=['A', 'B'])\n",
      " |      >>> df.groupby('A', as_index=False).head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  irow(self, i)\n",
      " |      DEPRECATED. Use ``.nth(i)`` instead\n",
      " |  \n",
      " |  last = f(self)\n",
      " |      Compute last of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  max = f(self)\n",
      " |      Compute max of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  mean(self, *args, **kwargs)\n",
      " |      Compute mean of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  median(self)\n",
      " |      Compute median of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  min = f(self)\n",
      " |      Compute min of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  nth(self, n, dropna=None)\n",
      " |      Take the nth row from each group if n is an int, or a subset of rows\n",
      " |      if n is a list of ints.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      Truthy (if a Series) or 'all', 'any' (if a DataFrame);\n",
      " |      this is equivalent to calling dropna(how=dropna) before the\n",
      " |      groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int or list of ints\n",
      " |          a single nth value for the row or a list of nth values\n",
      " |      dropna : None or str, optional\n",
      " |          apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Needs to be None, 'any' or 'all'\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      >>> g.nth(1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth(-1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  4.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      2  5.0\n",
      " |      \n",
      " |      Specifying ``dropna`` allows count ignoring NaN\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      NaNs denote group exhausted when using dropna\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |          B\n",
      " |      A\n",
      " |      1 NaN\n",
      " |      2 NaN\n",
      " |      \n",
      " |      Specifying ``as_index=False`` in ``groupby`` keeps the original index.\n",
      " |      \n",
      " |      >>> df.groupby('A', as_index=False).nth(1)\n",
      " |         A    B\n",
      " |      1  1  2.0\n",
      " |      4  2  5.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ohlc(self)\n",
      " |      Compute sum of values, excluding missing values\n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  pad(self, limit=None)\n",
      " |      Forward fill the values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : integer, optional\n",
      " |          limit of how many values to fill\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna\n",
      " |      DataFrame.fillna\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  prod = f(self)\n",
      " |      Compute prod of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper\n",
      " |      Return a new grouper with our resampler appended\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs)\n",
      " |      Return a rolling grouper, providing rolling\n",
      " |      functionaility per group\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sem(self, ddof=1)\n",
      " |      Compute standard error of the mean of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift each group by periods observations\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : integer, default 1\n",
      " |          number of periods to shift\n",
      " |      freq : frequency string\n",
      " |      axis : axis to shift, default 0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  size(self)\n",
      " |      Compute group sizes\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  std(self, ddof=1, *args, **kwargs)\n",
      " |      Compute standard deviation of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  sum = f(self)\n",
      " |      Compute sum of group values\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows of each group\n",
      " |      \n",
      " |      Essentially equivalent to ``.apply(lambda x: x.tail(n))``,\n",
      " |      except ignores as_index flag.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |                         columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      2  b  1\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  var(self, ddof=1, *args, **kwargs)\n",
      " |      Compute variance of groups, excluding missing values\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : integer, default 1\n",
      " |          degrees of freedom\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.groupby\n",
      " |      pandas.DataFrame.groupby\n",
      " |      pandas.Panel.groupby\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __init__(self, obj, keys=None, axis=0, level=None, grouper=None, exclusions=None, selection=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Groupby iterator\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by unicode(obj) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs)\n",
      " |      Apply function and combine results together in an intelligent way. The\n",
      " |      split-apply-combine combination rules attempt to be as common sense\n",
      " |      based as possible. For example:\n",
      " |      \n",
      " |      case 1:\n",
      " |      group DataFrame\n",
      " |      apply aggregation function (f(chunk) -> Series)\n",
      " |      yield DataFrame, with group axis having group labels\n",
      " |      \n",
      " |      case 2:\n",
      " |      group DataFrame\n",
      " |      apply transform function ((f(chunk) -> DataFrame with same indexes)\n",
      " |      yield DataFrame with resulting chunks glued together\n",
      " |      \n",
      " |      case 3:\n",
      " |      group Series\n",
      " |      apply function with f(chunk) -> DataFrame\n",
      " |      yield DataFrame with result of chunks glued together\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See online documentation for full exposition on how to use apply.\n",
      " |      \n",
      " |      In the current implementation apply calls func twice on the\n",
      " |      first group to decide whether it can take a fast or slow code\n",
      " |      path. This can lead to unexpected behavior if func has\n",
      " |      side-effects, as they will take effect twice for the first\n",
      " |      group.\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      aggregate, transform\n",
      " |  \n",
      " |  get_group(self, name, obj=None)\n",
      " |      Constructs NDFrame from group with provided name\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          the name of the group to get as a DataFrame\n",
      " |      obj : NDFrame, default None\n",
      " |          the NDFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      group : type of obj\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _GroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      dict {group name -> group labels}\n",
      " |  \n",
      " |  indices\n",
      " |      dict {group name -> group indices}\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  plot\n",
      " |      Class implementing the .plot attribute for groupby objects\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for a object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  ndim\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.core.groupby.DataFrameGroupBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[3 4 5]\n",
      "[6 7 8]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "N = 10\n",
    "a = np.arange(N)\n",
    "batchsize = 3\n",
    "n_batch = int((N-1)/batchsize + 1)\n",
    "for i in range(n_batch):\n",
    "    print(a[i*batchsize: (i+1)*batchsize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  0  1\n",
      "1  2  3\n",
      "2  4  5\n",
      "3  6  7\n",
      "4  8  9\n",
      "<class 'tuple'>\n",
      "2\n",
      "(0, 0    0\n",
      "1    1\n",
      "Name: 0, dtype: int64)\n",
      "<class 'tuple'>\n",
      "2\n",
      "(1, 0    2\n",
      "1    3\n",
      "Name: 1, dtype: int64)\n",
      "<class 'tuple'>\n",
      "2\n",
      "(2, 0    4\n",
      "1    5\n",
      "Name: 2, dtype: int64)\n",
      "<class 'tuple'>\n",
      "2\n",
      "(3, 0    6\n",
      "1    7\n",
      "Name: 3, dtype: int64)\n",
      "<class 'tuple'>\n",
      "2\n",
      "(4, 0    8\n",
      "1    9\n",
      "Name: 4, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(pd.DataFrame(np.arange(10).reshape(5, 2)))\n",
    "for v in pd.DataFrame(np.arange(10).reshape(5, 2)).iterrows():\n",
    "    print(type(v))\n",
    "    print(len(v))\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4], [5, 6], 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[[1, 2, 3], [4, 5], 3], [[2, 3, 4], [5, 6], 4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.array([1,3,5]).astype(np.int32), np.array([3,4,6]).astype(np.int32)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'floldl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8da2d2ac3cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloldl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'floldl'"
     ]
    }
   ],
   "source": [
    "help(tf.floldl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'while_loop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-03c8c9020dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'while_loop'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "help(tf.while_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(-1, 1+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
